{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSouo\n",
    "- 파서(html, xml 의 형태로 내려온 데이터를 원하는 요소만 찾기 위해 필요)\n",
    "- requests + bs4 : 이 조헙으로 주로 크롤링\n",
    "- 파서 종류\n",
    "    - html.parser (두번째로 빠름)\n",
    "    - lxml (속도가 가장 빠름) : 설치 필요 pip install lxml\n",
    "    - html5lib (가장 느림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>의대증원 오늘 확정…전공의·의대생 복귀 가능성 더 멀어졌다</title>\n",
      "<h3 class=\"tit_view\" data-translation=\"true\">의대증원 오늘 확정…전공의·의대생 복귀 가능성 더 멀어졌다</h3>\n",
      "의대증원 오늘 확정…전공의·의대생 복귀 가능성 더 멀어졌다\n",
      "{'class': ['tit_view'], 'data-translation': 'true'}\n"
     ]
    }
   ],
   "source": [
    "url = \"https://v.daum.net/v/20240524104849821\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    # print(r.text)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    # print(soup)\n",
    "    # print(soup.head)\n",
    "\n",
    "    # 요소 접근\n",
    "    # 1. 태그명 사용\n",
    "    print(soup.title) # <title>의대증원 오늘 확정…전공의·의대생 복귀 가능성 더 멀어졌다</title>\n",
    "    print(soup.h3) # <h3 class=\"tit_view\" data-translation=\"true\">의대증원 오늘 확정…전공의·의대생 복귀 가능성 더 멀어졌다</h3>\n",
    "    # get_text() : 태그의 텍스트만 추출\n",
    "    print(soup.title.get_text()) # 의대증원 오늘 확정…전공의·의대생 복귀 가능성 더 멀어졌다\n",
    "    # attrs : 태그의 속성만 추출\n",
    "    print(soup.h3.attrs) # {'class': ['tit_view'], 'data-translation': 'true'}\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title <title>The Dormouse's story</title>\n",
      "title content The Dormouse's story\n",
      "title content The Dormouse's story\n",
      "title parent <head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "====================\n",
      "p <p class=\"title\">\n",
      "<b> The Dormouse's story </b>\n",
      "</p>\n",
      "p The Dormouse's story\n",
      "p {'class': ['title']}\n",
      "p ['title']\n",
      "b <b> The Dormouse's story </b>\n",
      "b The Dormouse's story\n",
      "b {'class': ['title']}\n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    # print(r.text)\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    # print(soup)\n",
    "    # title 태그 가져오기\n",
    "    title = soup.title\n",
    "    # get_text(), string() 서로 상호보완적 \n",
    "    # get_text() 가 안되면 string() 쓰고, string()이 안되면 get_text() 쓰기\n",
    "    print(f\"title {title}\") # title <title>The Dormouse's story</title>\n",
    "    print(f\"title content {title.get_text()}\") # title content The Dormouse's story\n",
    "    print(f\"title content {title.string}\") # title content The Dormouse's story\n",
    "    print(f\"title parent {title.parent}\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # p 태그 가져오기\n",
    "    p1 = soup.p\n",
    "    print(f\"p {p1}\")\n",
    "    print(f\"p {p1.get_text().strip()}\") # strip : 공백 제거\n",
    "    print(f\"p {p1.attrs}\") # p {'class': ['title']} dict 구조\n",
    "    print(f\"p {p1[\"class\"]}\") # p ['title'] : key값 가져오기 가능\n",
    "    \n",
    "    # b 태그 가져오기\n",
    "    b1 = soup.b\n",
    "    print(f\"b {b1}\")\n",
    "    print(f\"b {b1.get_text().strip()}\") \n",
    "    print(f\"b {p1.attrs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p <p class=\"story\">\n",
      "      Once upon a time there were three little sisters; and their names were\n",
      "      <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "      ,\n",
      "      <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n",
      "      and\n",
      "      <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a>\n",
      "      ; and they lived at the bottom of a well.\n",
      "    </p>\n",
      "p Once upon a time there were three little sisters; and their names were\n",
      "       Elsie \n",
      "      ,\n",
      "       Lacie \n",
      "      and\n",
      "       Tillie \n",
      "      ; and they lived at the bottom of a well.\n",
      "p {'class': ['story']}\n",
      "p ['title']\n"
     ]
    }
   ],
   "source": [
    "# 요소 접근\n",
    "# 2. 문서의 구조를 이용한 요소 찾기\n",
    "# parent, children, next_sibling, ...\n",
    "\n",
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    # print(r.text)\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    \n",
    "    # body = soup.body\n",
    "    # print(f\"body children {body.children}\")\n",
    "    # for child in body.children:\n",
    "    #     print(child)\n",
    "\n",
    "    # 첫번째 p 요소 찾기\n",
    "    p1 = soup.p\n",
    "    # 두번째 p 요소 찾기\n",
    "    p2 = p1.find_next_sibling(\"p\")\n",
    "    print(f\"p {p2}\")\n",
    "    print(f\"p {p2.get_text().strip()}\")\n",
    "    # 오류 : AttributeError: 'NoneType' object has no attribute 'strip' / 못찾아서 strip을 쓸 수 없어\n",
    "    # print(f\"p {p2.string.strip()}\")\n",
    "    print(f\"p {p2.attrs}\")\n",
    "    print(f\"p {p1[\"class\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<title>The Dormouse's story</title>\n",
      "</head>\n",
      "<p class=\"title\">\n",
      "<b> The Dormouse's story </b>\n",
      "</p>\n",
      "<p class=\"story\">\n",
      "      Once upon a time there were three little sisters; and their names were\n",
      "      <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "      ,\n",
      "      <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n",
      "      and\n",
      "      <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a>\n",
      "      ; and they lived at the bottom of a well.\n",
      "    </p>\n",
      "<p class=\"story\">...</p>\n",
      "====================\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "http://example.com/tillie\n",
      "====================\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\"> Elsie </a>\n",
      "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\"> Lacie </a>\n",
      "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\"> Tillie </a>\n"
     ]
    }
   ],
   "source": [
    "# find() : 조건을 만족한느 요소 한개 찾기\n",
    "# find_all() : 조건을 만족하는 요소 모두 찾기\n",
    "\n",
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    # print(r.text)\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    head = soup.find(\"head\")\n",
    "    print(head)\n",
    "\n",
    "    # p1 = soup.find(\"p\")\n",
    "    # print(p1)\n",
    "\n",
    "    p1 = soup.find(\"p\", attrs={\"class\":\"title\"})\n",
    "    print(p1)\n",
    "\n",
    "    # p2 = soup.find(\"p\", attrs={\"class\":\"story\"})\n",
    "    p2 = soup.find(\"p\", class_=\"story\")\n",
    "    print(p2)\n",
    "\n",
    "    p_all = soup.find_all(\"p\", class_=\"story\")\n",
    "    # print(p_all)\n",
    "    print(p_all[1])\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "\n",
    "    # a1 = soup.find(\"a\",attrs={\"id\":\"link1\"})\n",
    "    a1 = soup.find(\"a\",id=\"link1\")\n",
    "    print(a1)\n",
    "\n",
    "    a3 = soup.find(\"a\",id=\"link3\")\n",
    "    print(a3[\"href\"])\n",
    "\n",
    "    print(\"=\" * 20)\n",
    "    a_tag = soup.find_all(\"a\")\n",
    "    for ele in a_tag:\n",
    "        print(ele)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elsie', 'Lacie', 'Tillie']\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
     ]
    }
   ],
   "source": [
    "url = \"./story.html\"\n",
    "\n",
    "with open(url, \"r\") as f:\n",
    "    r = f.read()\n",
    "    # print(r.text)\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "\n",
    "    link1= soup.find_all(string = [\"Elsie\",\"Lacie\",\"Tillie\"])\n",
    "    link2= soup.find_all(\"a\", string = [\"Elsie\",\"Lacie\",\"Tillie\"])\n",
    "    print(link1)\n",
    "    print(link2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna\n",
      "Pavlovna SchererEmpress Marya\n",
      "FedorovnaPrince Vasili KuraginAnna PavlovnaSt. Petersburgthe princeAnna PavlovnaAnna Pavlovnathe princethe princethe princePrince VasiliAnna PavlovnaAnna Pavlovnathe princeWintzingerodeKing of Prussiale Vicomte de MortemartMontmorencysRohansAbbe Moriothe Emperorthe princePrince VasiliDowager Empress Marya Fedorovnathe baronAnna Pavlovnathe Empressthe EmpressAnna Pavlovna'sHer MajestyBaron\n",
      "FunkeThe princeAnna\n",
      "Pavlovnathe EmpressThe princeAnatolethe princeThe princeAnna\n",
      "PavlovnaAnna PavlovnaWell, Prince, so Genoa and Lucca are now just family estates of the\n",
      "Buonapartes. But I warn you, if you don't tell me that this means war,\n",
      "if you still try to defend the infamies and horrors perpetrated by\n",
      "that Antichrist- I really believe he is Antichrist- I will have\n",
      "nothing more to do with you and you are no longer my friend, no longer\n",
      "my 'faithful slave,' as you call yourself! But how do you do? I see\n",
      "I have frightened you- sit down and tell me all the news.\n",
      "If you have nothing better to do, Count [or Prince], and if the\n",
      "prospect of spending an evening with a poor invalid is not too\n",
      "terrible, I shall be very charmed to see you tonight between 7 and 10-\n",
      "Annette Scherer.\n",
      "Heavens! what a virulent attack!\n",
      "First of all, dear friend, tell me how you are. Set your friend's\n",
      "mind at rest,\n",
      "Can one be well while suffering morally? Can one be calm in times\n",
      "like these if one has any feeling?\n",
      "You are\n",
      "staying the whole evening, I hope?\n",
      "And the fete at the English ambassador's? Today is Wednesday. I\n",
      "must put in an appearance there,\n",
      "My daughter is\n",
      "coming for me to take me there.\n",
      "I thought today's fete had been canceled. I confess all these\n",
      "festivities and fireworks are becoming wearisome.\n",
      "If they had known that you wished it, the entertainment would\n",
      "have been put off,\n",
      "Don't tease! Well, and what has been decided about Novosiltsev's\n",
      "dispatch? You know everything.\n",
      "What can one say about it?\n",
      "What has been decided? They have decided that\n",
      "Buonaparte has burnt his boats, and I believe that we are ready to\n",
      "burn ours.\n",
      "Oh, don't speak to me of Austria. Perhaps I don't understand\n",
      "things, but Austria never has wished, and does not wish, for war.\n",
      "She is betraying us! Russia alone must save Europe. Our gracious\n",
      "sovereign recognizes his high vocation and will be true to it. That is\n",
      "the one thing I have faith in! Our good and wonderful sovereign has to\n",
      "perform the noblest role on earth, and he is so virtuous and noble\n",
      "that God will not forsake him. He will fulfill his vocation and\n",
      "crush the hydra of revolution, which has become more terrible than\n",
      "ever in the person of this murderer and villain! We alone must\n",
      "avenge the blood of the just one.... Whom, I ask you, can we rely\n",
      "on?... England with her commercial spirit will not and cannot\n",
      "understand the Emperor Alexander's loftiness of soul. She has\n",
      "refused to evacuate Malta. She wanted to find, and still seeks, some\n",
      "secret motive in our actions. What answer did Novosiltsev get? None.\n",
      "The English have not understood and cannot understand the\n",
      "self-abnegation of our Emperor who wants nothing for himself, but only\n",
      "desires the good of mankind. And what have they promised? Nothing! And\n",
      "what little they have promised they will not perform! Prussia has\n",
      "always declared that Buonaparte is invincible, and that all Europe\n",
      "is powerless before him.... And I don't believe a word that Hardenburg\n",
      "says, or Haugwitz either. This famous Prussian neutrality is just a\n",
      "trap. I have faith only in God and the lofty destiny of our adored\n",
      "monarch. He will save Europe!\n",
      "I think,\n",
      "None\n",
      "In a moment. A propos,\n",
      "None\n",
      "I shall be delighted to meet them,\n",
      "But tell me,\n",
      "is it true that the Dowager Empress wants Baron Funke\n",
      "to be appointed first secretary at Vienna? The baron by all accounts\n",
      "is a poor creature.\n",
      "Baron Funke has been recommended to the Dowager Empress by her\n",
      "sister,\n",
      "Now about your family. Do you know that since your daughter came\n",
      "out everyone has been enraptured by her? They say she is amazingly\n",
      "beautiful.\n",
      "I often think,\n",
      "None\n",
      "Two such charming children. And really you appreciate\n",
      "them less than anyone, and so you don't deserve to have them.\n",
      "I can't help it,\n",
      "Lavater would have said I\n",
      "lack the bump of paternity.\n",
      "Don't joke; I mean to have a serious talk with you. Do you know I\n",
      "am dissatisfied with your younger son? Between ourselves\n",
      "he was mentioned at Her\n",
      "Majesty's and you were pitied....\n",
      "What would you have me do?\n",
      "You know I did all\n",
      "a father could for their education, and they have both turned out\n",
      "fools. Hippolyte is at least a quiet fool, but Anatole is an active\n",
      "one. That is the only difference between them.\n",
      "And why are children born to such men as you? If you were not a\n",
      "father there would be nothing I could reproach you with,\n",
      "I am your faithful slave and to you alone I can confess that my\n",
      "children are the bane of my life. It is the cross I have to bear. That\n",
      "is how I explain it to myself. It can't be helped!\n"
     ]
    }
   ],
   "source": [
    "url = \"https://pythonscraping.com/pages/warandpeace.html\"\n",
    "\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    # 등장인물 출력\n",
    "    names = soup.find_all(\"span\", class_=\"green\")\n",
    "    for name in names:\n",
    "        print(name.string, end=\"\")\n",
    "\n",
    "    # 대사 출력\n",
    "    talk = soup.find_all(\"span\", class_=\"red\")\n",
    "    for d in talk:\n",
    "        print(d.string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 : 의대증원 오늘 확정…전공의·의대생 복귀 가능성 더 멀어졌다\n",
      "작성자 : 천선휴 기자\n",
      "작성날짜와 시간 :2024. 5. 24. 10:48\n",
      "첫 번째 문단 : (서울=뉴스1) 천선휴 기자 = 2025학년도 의과대학 정원이 24일 확정된다. 1999년 이후 27년 만의 의대정원 증원이다. \n"
     ]
    }
   ],
   "source": [
    "url = \"https://v.daum.net/v/20240524104849821\"\n",
    "\n",
    "with requests.Session() as s:\n",
    "    r = s.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "\n",
    "    # 뉴스 제목\n",
    "    # title = soup.find(\"h3\", class_=\"tit_view\")\n",
    "    title = soup.h3\n",
    "    print(f\"제목 : {title.text}\")\n",
    "\n",
    "    # 작성자\n",
    "    writer = soup.find(\"span\", class_=\"txt_info\")\n",
    "    print(f\"작성자 : {writer.string}\")\n",
    "\n",
    "    # 작성날짜와 시간\n",
    "    date = soup.find(\"span\", class_=\"num_date\")\n",
    "    print(f\"작성날짜와 시간 :{date.string}\")\n",
    "\n",
    "    # 첫번째 문단 가져오기\n",
    "    para = soup.find(\"p\", attrs={\"dmcf-ptype\":\"general\"})\n",
    "    print(f\"첫 번째 문단 : {para.string}\")\n",
    "\n",
    "    # 전체 본문 내용 가져오기\n",
    "    para = soup.find_all(\"p\", attrs={\"dmcf-ptype\":\"general\"})\n",
    "    print(f\"전체 본문 : {para.string}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
